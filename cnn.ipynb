{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9a4299bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('Chinese_Names_Corpus（120W）.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bbc06c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['阿安', '阿彬', '阿斌', '阿滨', '阿冰', '阿冰冰', '阿兵', '阿婵']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "33485da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ab0b6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \n",
    "    def __init__(self,input_size,output_size,bias=True):\n",
    "        self.weight = torch.randn((input_size,output_size))\n",
    "        self.bias = torch.randn(output_size) if bias else None\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + [self.bias] if self.bias is not None else []\n",
    "\n",
    "class BatchNorm:\n",
    "    \n",
    "    def __init__(self,dim):\n",
    "        self.runing_mean = torch.zeros(dim)\n",
    "        self.runing_var = torch.ones(dim)\n",
    "        self.eps = 1e-5\n",
    "        self.training = True\n",
    "        self.gamma = torch.randn(dim)\n",
    "        self.beta = torch.randn(dim)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        if self.training:\n",
    "            x_mean = x.mean(dim=0,keepdims=True)\n",
    "            x_var = x.var(dim=0,keepdims=True)\n",
    "        else:\n",
    "            x_mean = self.runing_mean\n",
    "            x_var = self.runing_var\n",
    "        self.out = self.gamma*(x-x_mean)/torch.sqrt(x_var+self.eps)+self.beta\n",
    "        if self.training:\n",
    "            self.runing_mean = 0.999 * self.runing_mean + 0.001*x_mean\n",
    "            self.runing_var = 0.999 * self.runing_var + 0.001*x_var\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma,self.beta]\n",
    "\n",
    "    \n",
    "class Flatten:\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        self.out = x.view(len(x),-1)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "\n",
    "class Tanh:\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = torch.randn(vocab_size,embed_size)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.embed[x]\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.embed]\n",
    "\n",
    "class Sequential:\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params.extend(layer.parameters())\n",
    "        return params\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b4d9a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {}\n",
    "itos = {}\n",
    "stoi['.'] = 0\n",
    "itos[0] = '.'\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "for i,c in enumerate(chars):\n",
    "    stoi[c] = i+1\n",
    "    itos[i+1]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5dc48570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5ad812f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 5\n",
    "def get_data():\n",
    "    X = []\n",
    "    Y = []\n",
    "    for w in words:\n",
    "        context = [0]*block_size\n",
    "        for c in w + '.':\n",
    "            ix = stoi[c]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:]+[ix]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9ac9b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a5d2aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(stoi)\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e6be129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(vocab_size,embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "60c19db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Embedding(vocab_size,embed_size),\n",
    "    Flatten(),\n",
    "    Linear(embed_size*block_size,100),\n",
    "    BatchNorm(100),\n",
    "    Tanh(),\n",
    "    Linear(100,100),\n",
    "    BatchNorm(100),\n",
    "    Tanh(),\n",
    "    Linear(100,100),\n",
    "    BatchNorm(100),\n",
    "    Tanh(),\n",
    "    Linear(100,vocab_size),\n",
    "    BatchNorm(vocab_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0ecee6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "57a9b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f50a1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sequential.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8dc44b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a555e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.130544662475586\n",
      "4.906082630157471\n",
      "4.103755950927734\n",
      "4.410313129425049\n",
      "4.025326251983643\n",
      "4.489019393920898\n",
      "4.305686950683594\n",
      "4.775646686553955\n",
      "5.2324676513671875\n",
      "4.384654521942139\n",
      "4.132236480712891\n",
      "3.981794834136963\n",
      "4.626075744628906\n",
      "3.5692386627197266\n",
      "4.354118347167969\n",
      "4.857334136962891\n",
      "4.904262542724609\n",
      "4.51820707321167\n",
      "4.5569167137146\n",
      "4.9520649909973145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[222], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m      9\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m lr \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/local_nmt/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/local_nmt/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(400000):\n",
    "    \n",
    "    idxs = torch.randint(0,len(X),(batch_size,))\n",
    "    Xtr = X[idxs] # b,T,C\n",
    "    Ytr = Y[idxs]\n",
    "    logits = sequential(Xtr)\n",
    "    loss = F.cross_entropy(logits,Ytr)\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr =  0.01 if i < 10000 else 0.001\n",
    "    for p in params:\n",
    "        p.data += -lr*p.grad\n",
    "    if i % 10000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ff53b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "45fe0338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['胡']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ff23e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "胡景荻\n",
      "胡乐暖\n",
      "胡亚晓\n",
      "胡舜店\n",
      "胡年居\n",
      "胡夔\n",
      "胡坤志\n",
      "胡民芬\n",
      "胡绯文\n",
      "胡滕万\n",
      "胡正卓\n",
      "胡波超\n",
      "胡超红\n",
      "胡共忠\n",
      "胡黄安\n",
      "胡康辉\n",
      "胡霞林\n",
      "胡建婴\n",
      "胡僖斌\n",
      "胡帝\n",
      "胡磬观\n",
      "胡牙冕\n",
      "胡日\n",
      "胡庠\n",
      "胡玉媛\n",
      "胡良诚\n",
      "胡家岱\n",
      "胡秀潮\n",
      "胡浑烟\n",
      "胡宏清\n",
      "胡冶生\n",
      "胡黎妤\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    ix = 1659\n",
    "    context = [0]*(block_size-1)+[ix]\n",
    "    w = []\n",
    "    while True:\n",
    "        w.append(itos[ix])\n",
    "        x = torch.tensor(context).view(1,-1)\n",
    "        logits = sequential(x)\n",
    "        probs = F.softmax(logits,dim=1)\n",
    "        ix = torch.multinomial(probs,num_samples=1).item()\n",
    "        context = context[1:]+[ix]\n",
    "        if ix == 0:\n",
    "            break\n",
    "    name = ''.join(w)\n",
    "    if name not in words:\n",
    "        print(''.join(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4a562ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['刘']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1a106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_nmt",
   "language": "python",
   "name": "local_nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
